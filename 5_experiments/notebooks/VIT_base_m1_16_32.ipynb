{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7v2dPqfZFIV"
      },
      "source": [
        "#### Libraries Imported and Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3bQIxfD9Ep0y"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/nguyenvd_drone/miniconda3/envs/andt/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch import functional as F\n",
        "from torch import optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "from scipy.ndimage import gaussian_filter\n",
        "import time\n",
        "from datetime import timedelta\n",
        "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YS7R221iUMI0",
        "outputId": "b7022893-723e-450d-e4b7-19af86ceb89f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU:  NVIDIA GeForce RTX 2080 Ti\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print('GPU: ', torch.cuda.get_device_name(0))\n",
        "\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print('No GPU available')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4age-c6nWquv",
        "outputId": "d7397f9d-8b08-486e-a7ac-c8054b652dde"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Đã chuyển đến /storageStudents/ncsmmlab/tungufm/VitFromScratch/notebooks\n"
          ]
        }
      ],
      "source": [
        "work_dir = '/storageStudents/ncsmmlab/tungufm/VitFromScratch/notebooks'\n",
        "os.chdir(work_dir)\n",
        "print(f\"Đã chuyển đến {os.getcwd()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFc5EfTgZIBk"
      },
      "source": [
        "#### Model Architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_75W0devEPY7"
      },
      "source": [
        "**Vision Transformer Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "idmPOFlDIGDZ"
      },
      "outputs": [],
      "source": [
        "class Attention(nn.Module):\n",
        "    '''\n",
        "    Attention Module used to perform self-attention operation allowing the model to attend\n",
        "    information from different representation subspaces on an input sequence of embeddings.\n",
        "    The sequence of operations is as follows :-\n",
        "\n",
        "    Input -> Query, Key, Value -> ReshapeHeads -> Query.TransposedKey -> Softmax -> Dropout\n",
        "    -> AttentionScores.Value -> ReshapeHeadsBack -> Output\n",
        "\n",
        "    Args:\n",
        "        embed_dim: Dimension size of the hidden embedding\n",
        "        heads: Number of parallel attention heads (Default=8)\n",
        "        activation: Optional activation function to be applied to the input while\n",
        "                    transforming to query, key and value matrixes (Default=None)\n",
        "        dropout: Dropout value for the layer on attention_scores (Default=0.1)\n",
        "\n",
        "    Methods:\n",
        "        _reshape_heads(inp) :-\n",
        "        Changes the input sequence embeddings to reduced dimension according to the number\n",
        "        of attention heads to parallelize attention operation\n",
        "        (batch_size, seq_len, embed_dim) -> (batch_size * heads, seq_len, reduced_dim)\n",
        "\n",
        "        _reshape_heads_back(inp) :-\n",
        "        Changes the reduced dimension due to parallel attention heads back to the original\n",
        "        embedding size\n",
        "        (batch_size * heads, seq_len, reduced_dim) -> (batch_size, seq_len, embed_dim)\n",
        "\n",
        "        forward(inp) :-\n",
        "        Performs the self-attention operation on the input sequence embedding.\n",
        "        Returns the output of self-attention as well as atttention scores\n",
        "        (batch_size, seq_len, embed_dim) -> (batch_size, seq_len, embed_dim), (batch_size * heads, seq_len, seq_len)\n",
        "\n",
        "    Examples:\n",
        "        >>> attention = Attention(embed_dim, heads, activation, dropout)\n",
        "        >>> out, weights = attention(inp)\n",
        "    '''\n",
        "    def __init__(self, embed_dim, heads=8, activation=None, dropout=0.1):\n",
        "        super(Attention, self).__init__()\n",
        "        self.heads = heads\n",
        "        self.embed_dim = embed_dim\n",
        "        self.query = nn.Linear(embed_dim, embed_dim)\n",
        "        self.key = nn.Linear(embed_dim, embed_dim)\n",
        "        self.value = nn.Linear(embed_dim, embed_dim)\n",
        "        self.softmax = nn.Softmax(dim=-1)\n",
        "        if activation == 'relu':\n",
        "            self.activation = nn.ReLU()\n",
        "        else:\n",
        "            self.activation = nn.Identity()\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, inp):\n",
        "        # inp: (batch_size, seq_len, embed_dim)\n",
        "        batch_size, seq_len, embed_dim = inp.size()\n",
        "        assert embed_dim == self.embed_dim\n",
        "\n",
        "        query = self.activation(self.query(inp))\n",
        "        key   = self.activation(self.key(inp))\n",
        "        value = self.activation(self.value(inp))\n",
        "\n",
        "        # output of _reshape_heads(): (batch_size * heads, seq_len, reduced_dim) | reduced_dim = embed_dim // heads\n",
        "        query = self._reshape_heads(query)\n",
        "        key   = self._reshape_heads(key)\n",
        "        value = self._reshape_heads(value)\n",
        "\n",
        "        # attention_scores: (batch_size * heads, seq_len, seq_len) | Softmaxed along the last dimension\n",
        "        attention_scores = self.softmax(torch.matmul(query, key.transpose(1, 2)))\n",
        "\n",
        "        # out: (batch_size * heads, seq_len, reduced_dim)\n",
        "        out = torch.matmul(self.dropout(attention_scores), value)\n",
        "\n",
        "        # output of _reshape_heads_back(): (batch_size, seq_len, embed_size)\n",
        "        out = self._reshape_heads_back(out)\n",
        "\n",
        "        return out, attention_scores\n",
        "\n",
        "    def _reshape_heads(self, inp):\n",
        "        # inp: (batch_size, seq_len, embed_dim)\n",
        "        batch_size, seq_len, embed_dim = inp.size()\n",
        "\n",
        "        reduced_dim = self.embed_dim // self.heads\n",
        "        assert reduced_dim * self.heads == self.embed_dim\n",
        "        out = inp.reshape(batch_size, seq_len, self.heads, reduced_dim)\n",
        "        out = out.permute(0, 2, 1, 3)\n",
        "        out = out.reshape(-1, seq_len, reduced_dim)\n",
        "\n",
        "        # out: (batch_size * heads, seq_len, reduced_dim)\n",
        "        return out\n",
        "\n",
        "    def _reshape_heads_back(self, inp):\n",
        "        # inp: (batch_size * heads, seq_len, reduced_dim) | reduced_dim = embed_dim // heads\n",
        "        batch_size_mul_heads, seq_len, reduced_dim = inp.size()\n",
        "        batch_size = batch_size_mul_heads // self.heads\n",
        "\n",
        "        out = inp.reshape(batch_size, self.heads, seq_len, reduced_dim)\n",
        "        out = out.permute(0, 2, 1, 3)\n",
        "        out = out.reshape(batch_size, seq_len, self.embed_dim)\n",
        "\n",
        "        # out: (batch_size, seq_len, embed_dim)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "XYemII1gElcK"
      },
      "outputs": [],
      "source": [
        "# Check if Dropout should be used after second Linear Layer\n",
        "class FeedForward(nn.Module):\n",
        "    '''\n",
        "    FeedForward Network with two sequential linear layers with GELU activation function\n",
        "    ,applied to the output of self attention operation. The sequence of operations is as\n",
        "    follows :-\n",
        "\n",
        "    Input -> FC1 -> GELU -> Dropout -> FC2 -> Output\n",
        "\n",
        "    Args:\n",
        "        embed_dim: Dimension size of the hidden embedding\n",
        "        forward_expansion: The scale used to transform the input embedding to a higher dimension\n",
        "                           and then scaled back to capture richer information (Default=1)\n",
        "        dropout: Dropout value for the layer on attention_scores (Default=0.1)\n",
        "\n",
        "    Methods:\n",
        "        forward(inp) :-\n",
        "        Applies the sequence of operations mentioned above.\n",
        "        (batch_size, seq_len, embed_dim) -> (batch_size, seq_len, embed_dim)\n",
        "\n",
        "    Examples:\n",
        "        >>> FF = FeedForward(8, 1)\n",
        "        >>> out = FF(inp)\n",
        "    '''\n",
        "    def __init__(self, embed_dim, forward_expansion=1, dropout=0.1):\n",
        "        super(FeedForward, self).__init__()\n",
        "        self.embed_dim = embed_dim\n",
        "        self.fc1 = nn.Linear(embed_dim, embed_dim * forward_expansion)\n",
        "        self.activation = nn.GELU()\n",
        "        self.fc2 = nn.Linear(embed_dim * forward_expansion, embed_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, inp):\n",
        "        # inp: (batch_size, seq_len, embed_dim)\n",
        "        batch_size, seq_len, embed_dim = inp.size()\n",
        "        assert embed_dim == self.embed_dim\n",
        "\n",
        "        out = self.dropout(self.activation(self.fc1(inp)))\n",
        "        # out = self.dropout(self.fc2(out))\n",
        "        out = self.fc2(out)\n",
        "\n",
        "        # out: (batch_size, seq_len, embed_dim)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "uMrCi7DNGvCc"
      },
      "outputs": [],
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "    '''\n",
        "    Transformer Block combines both the attention module and the feed forward module with layer\n",
        "    normalization, dropout and residual connections. The sequence of operations is as follows :-\n",
        "\n",
        "    Input -> LayerNorm1 -> Attention -> Residual -> LayerNorm2 -> FeedForward -> Output\n",
        "      |                                   |  |                                      |\n",
        "      |-------------Addition--------------|  |---------------Addition---------------|\n",
        "\n",
        "    Args:\n",
        "        embed_dim: Dimension size of the hidden embedding\n",
        "        heads: Number of parallel attention heads (Default=8)\n",
        "        activation: Optional activation function to be applied to the input while\n",
        "                    transforming to query, key and value matrixes (Default=None)\n",
        "        forward_expansion: The scale used to transform the input embedding to a higher dimension\n",
        "                           and then scaled back to capture richer information (Default=1)\n",
        "        dropout: Dropout value for the layer on attention_scores (Default=0.1)\n",
        "\n",
        "    Methods:\n",
        "        forward(inp) :-\n",
        "        Applies the sequence of operations mentioned above.\n",
        "        (batch_size, seq_len, embed_dim) -> (batch_size, seq_len, embed_dim)\n",
        "\n",
        "    Examples:\n",
        "        >>> TB = TransformerBlock(embed_dim, heads, activation, forward_expansion, dropout)\n",
        "        >>> out = TB(inp)\n",
        "    '''\n",
        "    def __init__(self, embed_dim, heads=8, activation=None, forward_expansion=1, dropout=0.1):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        self.embed_dim = embed_dim\n",
        "        self.norm1 = nn.LayerNorm(embed_dim)\n",
        "        self.attention = Attention(embed_dim, heads, activation, dropout)\n",
        "        self.norm2 = nn.LayerNorm(embed_dim)\n",
        "        self.feed_forward = FeedForward(embed_dim, forward_expansion, dropout)\n",
        "\n",
        "    def forward(self, inp):\n",
        "        # inp: (batch_size, seq_len, embed_dim)\n",
        "        batch_size, seq_len, embed_dim = inp.size()\n",
        "        assert embed_dim == self.embed_dim\n",
        "\n",
        "        res = inp\n",
        "        out = self.norm1(inp)\n",
        "        out, _ = self.attention(out)\n",
        "        out = out + res\n",
        "\n",
        "        res = out\n",
        "        out = self.norm2(out)\n",
        "        out = self.feed_forward(out)\n",
        "        out = out + res\n",
        "\n",
        "        # out: (batch_size, seq_len, embed_dim)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "kcBcReoPJ4NC"
      },
      "outputs": [],
      "source": [
        "class Transformer(nn.Module):\n",
        "    '''\n",
        "    Transformer combines multiple layers of Transformer Blocks in a sequential manner. The sequence\n",
        "    of the operations is as follows -\n",
        "\n",
        "    Input -> TB1 -> TB2 -> .......... -> TBn (n being the number of layers) -> Output\n",
        "\n",
        "    Args:\n",
        "        embed_dim: Dimension size of the hidden embedding\n",
        "        layers: Number of Transformer Blocks in the Transformer\n",
        "        heads: Number of parallel attention heads (Default=8)\n",
        "        activation: Optional activation function to be applied to the input while\n",
        "                    transforming to query, key and value matrixes (Default=None)\n",
        "        forward_expansion: The scale used to transform the input embedding to a higher dimension\n",
        "                           and then scaled back to capture richer information (Default=1)\n",
        "        dropout: Dropout value for the layer on attention_scores (Default=0.1)\n",
        "\n",
        "    Methods:\n",
        "        forward(inp) :-\n",
        "        Applies the sequence of operations mentioned above.\n",
        "        (batch_size, seq_len, embed_dim) -> (batch_size, seq_len, embed_dim)\n",
        "\n",
        "    Examples:\n",
        "        >>> transformer = Transformer(embed_dim, layers, heads, activation, forward_expansion, dropout)\n",
        "        >>> out = transformer(inp)\n",
        "    '''\n",
        "    def __init__(self, embed_dim, layers, heads=8, activation=None, forward_expansion=1, dropout=0.1):\n",
        "        super(Transformer, self).__init__()\n",
        "        self.embed_dim = embed_dim\n",
        "        self.trans_blocks = nn.ModuleList(\n",
        "            [TransformerBlock(embed_dim, heads, activation, forward_expansion, dropout) for i in range(layers)]\n",
        "        )\n",
        "\n",
        "    def forward(self, inp):\n",
        "        # inp: (batch_size, seq_len, embed_dim)\n",
        "\n",
        "        out = inp\n",
        "        for block in self.trans_blocks:\n",
        "            out = block(out)\n",
        "\n",
        "        # out: (batch_size, seq_len, embed_dim)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "XRN2k5-kLWYG"
      },
      "outputs": [],
      "source": [
        "# Not Exactly Same as Paper\n",
        "class ClassificationHead(nn.Module):\n",
        "    '''\n",
        "    Classification Head attached to the first sequence token which is used as the arbitrary\n",
        "    classification token and used to optimize the transformer model by applying Cross-Entropy\n",
        "    loss. The sequence of operations is as follows :-\n",
        "\n",
        "    Input -> FC1 -> GELU -> Dropout -> FC2 -> Output\n",
        "\n",
        "    Args:\n",
        "        embed_dim: Dimension size of the hidden embedding\n",
        "        classes: Number of classification classes in the dataset\n",
        "        dropout: Dropout value for the layer on attention_scores (Default=0.1)\n",
        "\n",
        "    Methods:\n",
        "        forward(inp) :-\n",
        "        Applies the sequence of operations mentioned above.\n",
        "        (batch_size, embed_dim) -> (batch_size, classes)\n",
        "\n",
        "    Examples:\n",
        "        >>> CH = ClassificationHead(embed_dim, classes, dropout)\n",
        "        >>> out = CH(inp)\n",
        "    '''\n",
        "    def __init__(self, embed_dim, classes, dropout=0.1):\n",
        "        super(ClassificationHead, self).__init__()\n",
        "        self.embed_dim = embed_dim\n",
        "        self.classes = classes\n",
        "        self.fc1 = nn.Linear(embed_dim, embed_dim // 2)\n",
        "        self.activation = nn.GELU()\n",
        "        self.fc2 = nn.Linear(embed_dim // 2, classes)\n",
        "        self.softmax = nn.Softmax(dim=-1)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, inp):\n",
        "        # inp: (batch_size, embed_dim)\n",
        "        batch_size, embed_dim = inp.size()\n",
        "        assert embed_dim == self.embed_dim\n",
        "\n",
        "        out = self.dropout(self.activation(self.fc1(inp)))\n",
        "        # out = self.softmax(self.fc2(out))\n",
        "        out = self.fc2(out)\n",
        "\n",
        "        # out: (batch_size, classes)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "M-8nXI7gPxIs"
      },
      "outputs": [],
      "source": [
        "class VisionTransformer(nn.Module):\n",
        "    '''\n",
        "    Vision Transformer is the complete end to end model architecture which combines all the above modules\n",
        "    in a sequential manner. The sequence of the operations is as follows -\n",
        "\n",
        "    Input -> CreatePatches -> ClassToken, PatchToEmbed , PositionEmbed -> Transformer -> ClassificationHead -> Output\n",
        "                                   |            | |                |\n",
        "                                   |---Concat---| |----Addition----|\n",
        "\n",
        "    Args:\n",
        "        patch_size: Length of square patch size\n",
        "        max_len: Max length of learnable positional embedding\n",
        "        embed_dim: Dimension size of the hidden embedding\n",
        "        classes: Number of classes in the dataset\n",
        "        layers: Number of Transformer Blocks in the Transformer\n",
        "        channels: Number of channels in the input (Default=3)\n",
        "        heads: Number of parallel attention heads (Default=8)\n",
        "        activation: Optional activation function to be applied to the input while\n",
        "                    transforming to query, key and value matrixes (Default=None)\n",
        "        forward_expansion: The scale used to transform the input embedding to a higher dimension\n",
        "                           and then scaled back to capture richer information (Default=1)\n",
        "        dropout: Dropout value for the layer on attention_scores (Default=0.1)\n",
        "\n",
        "    Methods:\n",
        "        forward(inp) :-\n",
        "        Applies the sequence of operations mentioned above.\n",
        "        It outputs the classification output as well as the sequence output of the transformer\n",
        "        (batch_size, channels, width, height) -> (batch_size, classes), (batch_size, seq_len+1, embed_dim)\n",
        "\n",
        "    Examples:\n",
        "        >>> ViT = VisionTransformer(atch_size, max_len, embed_dim, classes, layers, channels, heads, activation, forward_expansion, dropout)\n",
        "        >>> class_out, hidden_seq = ViT(inp)\n",
        "    '''\n",
        "    def __init__(self, patch_size, max_len, embed_dim, classes, layers, channels=3, heads=8, activation=None, forward_expansion=1, dropout=0.1):\n",
        "        super(VisionTransformer, self).__init__()\n",
        "        self.name = 'VisionTransformer'\n",
        "        self.patch_size = patch_size\n",
        "        self.embed_dim = embed_dim\n",
        "        self.channels = channels\n",
        "        self.patch_to_embed = nn.Linear(patch_size * patch_size * channels, embed_dim)\n",
        "        self.position_embed = nn.Parameter(torch.randn((max_len, embed_dim)))\n",
        "        self.transformer = Transformer(embed_dim, layers, heads, activation, forward_expansion, dropout)\n",
        "        self.classification_head = ClassificationHead(embed_dim, classes)\n",
        "        self.class_token = nn.Parameter(torch.zeros(1, 1, embed_dim))\n",
        "\n",
        "    def forward(self, inp):\n",
        "        # inp: (batch_size, channels, width, height)\n",
        "        batch_size, channels, width, height = inp.size()\n",
        "        assert channels == self.channels\n",
        "\n",
        "        out = inp.unfold(2, self.patch_size, self.patch_size).unfold(3, self.patch_size, self.patch_size).contiguous()\n",
        "        out = out.view(batch_size, channels, -1, self.patch_size, self.patch_size)\n",
        "        out = out.permute(0, 2, 3, 4, 1)\n",
        "        # out: (batch_size, seq_len, patch_size, patch_size, channels) | seq_len would be (width*height)/(patch_size**2)\n",
        "        batch_size, seq_len, patch_size, _, channels = out.size()\n",
        "\n",
        "        out = out.reshape(batch_size, seq_len, -1)\n",
        "        out = self.patch_to_embed(out)\n",
        "        # out: (batch_size, seq_len, embed_dim)\n",
        "\n",
        "        class_token = self.class_token.expand(batch_size, -1, -1)\n",
        "        out = torch.cat([class_token, out], dim=1)\n",
        "        # out: (batch_size, seq_len+1, embed_dim)\n",
        "\n",
        "        position_embed = self.position_embed[:seq_len+1]\n",
        "        position_embed = position_embed.unsqueeze(0).expand(batch_size, seq_len+1, self.embed_dim)\n",
        "        out = out + position_embed\n",
        "        # out: (batch_size, seq_len+1, embed_dim) | Added Positional Embeddings\n",
        "\n",
        "        out = self.transformer(out)\n",
        "        # out: (batch_size, seq_len+1, embed_dim)\n",
        "        class_token = out[:, 0]\n",
        "        # class_token: (batch_size, embed_dim)\n",
        "\n",
        "        class_out = self.classification_head(class_token)\n",
        "        # class_out: (batch_size, classes)\n",
        "\n",
        "        return class_out, out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "hJPR42t1S9li"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision.models import resnet34\n",
        "\n",
        "class ResNetFeatures(nn.Module):\n",
        "    '''\n",
        "    ResNetFeatures outputs the lower level features from pretrained ResNet34 till the intial 5 layers\n",
        "    (conv1, bn1, relu, maxpool, layer1(3 conv layers)) to be used in the hybrid architecture to be\n",
        "    able to kickstart the learining faster. The sequence of operations is as follows :-\n",
        "\n",
        "    Input -> conv1 -> bn1 -> relu -> maxpool -> layer1 -> Output\n",
        "\n",
        "    Args:\n",
        "        No arguments required\n",
        "\n",
        "    Methods:\n",
        "        forward(inp) :-\n",
        "        Applies the sequence of operations mentioned above.\n",
        "        (batch_size, 3, 224, 224) -> (batch_size, 64, 56, 56)\n",
        "\n",
        "    Examples:\n",
        "        >>> resnet_features = ResNetFeatures()\n",
        "        >>> out = resnet_features(inp)\n",
        "    '''\n",
        "    def __init__(self):\n",
        "        super(ResNetFeatures, self).__init__()\n",
        "        layers = list(resnet34(pretrained=True).children())[:5] #all layer expect last layer\n",
        "        self.feature_extractor = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, inp):\n",
        "        # inp: (batch_size, 3, 224, 224)\n",
        "\n",
        "        out = self.feature_extractor(inp)\n",
        "\n",
        "        # out: (batch_size, 64, 56, 56)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BsEV_yqAETZA"
      },
      "source": [
        "##### ResNet Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "eUMIU5BMjmeD"
      },
      "outputs": [],
      "source": [
        "class ResidualBlockSmall(nn.Module):\n",
        "    '''\n",
        "    ResidualBlockSmall implements the smaller block of the Residual Networks. It optionally also downsamples\n",
        "    the input according to the stride to match the output while adding the residual. The sequence of operations\n",
        "    is as follows :-\n",
        "\n",
        "    Input -> Conv1 -> BNorm1 -> ReLU -> Conv2 -> BNorm2 -> ReLU -> Output\n",
        "      |                                                              |\n",
        "      |-----------------Residual_Downsample (Optional)---------------|\n",
        "\n",
        "    Args:\n",
        "        input_channels: Number of input channels\n",
        "        out_channels: Number of output channels\n",
        "        residual_downsample: Residual Downsample dependent on if either height, width or channels change\n",
        "        stride: Stride value for the convolutional layers (Default=1)\n",
        "\n",
        "    Methods:\n",
        "        forward(inp) :-\n",
        "        Applies the sequence of operations mentioned above.\n",
        "        (batch_size, input_channels, height, width) -> (batch_size, out_channels, height, width)\n",
        "\n",
        "    Examples:\n",
        "        >>> RBS = ResidualBlockSmall(input_channels, out_channels, residual_downsample, stride)\n",
        "        >>> out = RBS(inp)\n",
        "    '''\n",
        "    def __init__(self, input_channels, out_channels, residual_downsample=None, stride=1):\n",
        "        super(ResidualBlockSmall, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(input_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
        "        self.bnorm1 = nn.BatchNorm2d(out_channels)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
        "        self.bnorm2 = nn.BatchNorm2d(out_channels)\n",
        "        self.activation = nn.ReLU()\n",
        "        self.residual_downsample = residual_downsample\n",
        "\n",
        "    def forward(self, inp):\n",
        "        # inp: (batch_size, input_channels, height, width)\n",
        "\n",
        "        res = inp\n",
        "        out = self.activation(self.bnorm1(self.conv1(inp)))\n",
        "        out = self.activation(self.bnorm2(self.conv2(out)))\n",
        "\n",
        "        if self.residual_downsample is not None:\n",
        "            res = self.residual_downsample(res)\n",
        "\n",
        "        out = self.activation(out + res)\n",
        "\n",
        "        # out: (batch_size, out_channels, height, width) | height, width depending on stride\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "KvBRaEPVktZd"
      },
      "outputs": [],
      "source": [
        "class ResNetSmall(nn.Module):\n",
        "    '''\n",
        "    ResNetSmall consists of layers of the smaller residual block defined above (ResidualBlockSmall).\n",
        "    The layers are the residual blocks. The sequence of operations is as follows :-\n",
        "\n",
        "    Input -> Conv1 -> BNorm1 -> ReLU -> MaxPool -> Layer1 -> Layer2 -> Layer3 -> Layer4 -> AvgPool -> FC\n",
        "\n",
        "    Args:\n",
        "        layers: A four value array containing number of conv layers in each residual block\n",
        "        input_channels: number of input channels\n",
        "        classes: Number of classes in the dataset\n",
        "\n",
        "    Methods:\n",
        "        _layer(num_layers (Number of conv layers)\n",
        "               ,input_channels (Number of input channels)\n",
        "               ,output_channels (Number of output channels)\n",
        "               ,stride (Stride value for conv layer)) :-\n",
        "        Returns the sequential wrapper with all the layers in the residual block constructed according\n",
        "        to the parameters.\n",
        "\n",
        "        forward(inp) :-\n",
        "        Applies the sequence of operations mentioned above.\n",
        "        (batch_size, input_channels, height, width) -> (batch_size, classes)\n",
        "\n",
        "    Examples:\n",
        "        >>> resnet = ResNetSmall(layers, input_channels, classes)\n",
        "        >>> out = resnet(inp)\n",
        "    '''\n",
        "    def __init__(self, layers, input_channels, classes):\n",
        "        super(ResNetSmall, self).__init__()\n",
        "        self.name = 'ResNet'\n",
        "        self.conv1 = nn.Conv2d(input_channels, 64, kernel_size=7, stride=2, padding=3)\n",
        "        self.bnorm1 = nn.BatchNorm2d(64)\n",
        "        self.activation = nn.ReLU()\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "        self.layer1 = self._layer(layers[0], input_channels=64, output_channels=64, stride=1)\n",
        "        self.layer2 = self._layer(layers[1], input_channels=64, output_channels=128, stride=2)\n",
        "        self.layer3 = self._layer(layers[2], input_channels=128, output_channels=256, stride=2)\n",
        "        self.layer4 = self._layer(layers[3], input_channels=256, output_channels=512, stride=2)\n",
        "\n",
        "        self.avppool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(512, classes)\n",
        "\n",
        "    def forward(self, inp):\n",
        "        # inp: (batch_size, input_channels, height, width)\n",
        "\n",
        "        out = self.activation(self.bnorm1(self.conv1(inp)))\n",
        "        out = self.maxpool(out)\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "\n",
        "        out = self.avppool(out)\n",
        "        out = out.reshape(out.shape[0], -1)\n",
        "        out = self.fc(out)\n",
        "\n",
        "        # out: (batch_size, classes)\n",
        "        return out\n",
        "\n",
        "    def _layer(self, num_layers, input_channels, output_channels, stride):\n",
        "        residual_downsample = None\n",
        "        layers = []\n",
        "\n",
        "        if stride != 1:\n",
        "            residual_downsample = nn.Sequential(\n",
        "                nn.Conv2d(input_channels, output_channels, kernel_size=1, stride=stride),\n",
        "                nn.BatchNorm2d(output_channels * 4)\n",
        "            )\n",
        "\n",
        "        layers.append(ResidualBlockSmall(input_channels, output_channels, residual_downsample, stride))\n",
        "\n",
        "        for i in range(num_layers - 1):\n",
        "            layers.append(ResidualBlockSmall(output_channels, output_channels))\n",
        "\n",
        "        return nn.Sequential(*layers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "vQxpId2jEV_R"
      },
      "outputs": [],
      "source": [
        "class ResidualBlockLarge(nn.Module):\n",
        "    '''\n",
        "    ResidualBlockLarge implements the larger block of the Residual Networks. It optionally also downsamples\n",
        "    the input according to the stride or output channels to match the output while adding the residual. The\n",
        "    sequence of operations is as follows :-\n",
        "\n",
        "    Input -> Conv1 -> BNorm1 -> ReLU -> Conv2 -> BNorm2 -> ReLU -> Conv3 -> BNorm3 -> ReLU -> Output\n",
        "      |                                                                                          |\n",
        "      |-----------------------------Residual_Downsample (Optional)-------------------------------|\n",
        "\n",
        "    Args:\n",
        "        input_channels: Number of input channels\n",
        "        out_channels: Number of output channels\n",
        "        residual_downsample: Residual Downsample dependent on if either height, width or channels change\n",
        "        stride: Stride value for the convolutional layers (Default=1)\n",
        "        expansion: Expansion of the input channels during convolutions (Default=4)\n",
        "\n",
        "    Methods:\n",
        "        forward(inp) :-\n",
        "        Applies the sequence of operations mentioned above.\n",
        "        (batch_size, input_channels, height, width) -> (batch_size, out_channels * expansion, height, width)\n",
        "\n",
        "    Examples:\n",
        "        >>> RBL = ResidualBlockLarge(input_channels, out_channels, residual_downsample, stride, expansion)\n",
        "        >>> out = RBL(inp)\n",
        "    '''\n",
        "    def __init__(self, input_channels, out_channels, residual_downsample=None, stride=1, expansion=4):\n",
        "        super(ResidualBlockLarge, self).__init__()\n",
        "        self.expansion = expansion\n",
        "        self.conv1 = nn.Conv2d(input_channels, out_channels, kernel_size=1, stride=1, padding=0)\n",
        "        self.bnorm1 = nn.BatchNorm2d(out_channels)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
        "        self.bnorm2 = nn.BatchNorm2d(out_channels)\n",
        "        self.conv3 = nn.Conv2d(out_channels, out_channels * expansion, kernel_size=1, stride=1, padding=0)\n",
        "        self.bnorm3 = nn.BatchNorm2d(out_channels * expansion)\n",
        "        self.activation = nn.ReLU()\n",
        "        self.residual_downsample = residual_downsample\n",
        "\n",
        "    def forward(self, inp):\n",
        "        # inp: (batch_size, input_channels, height, width)\n",
        "\n",
        "        res = inp\n",
        "        out = self.activation(self.bnorm1(self.conv1(inp)))\n",
        "        out = self.activation(self.bnorm2(self.conv2(out)))\n",
        "        out = self.activation(self.bnorm3(self.conv3(out)))\n",
        "\n",
        "        if self.residual_downsample is not None:\n",
        "            res = self.residual_downsample(res)\n",
        "\n",
        "        out = self.activation(out + res)\n",
        "\n",
        "        # out: (batch_size, out_channels * expansion, height, width) | height, width depending on stride\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "6ss--kZkSGNU"
      },
      "outputs": [],
      "source": [
        "class ResNetLarge(nn.Module):\n",
        "    '''\n",
        "    ResNetLarge consists of layers of the larger residual block defined above (ResidualBlockLarger).\n",
        "    The layers are the residual blocks. The sequence of operations is as follows :-\n",
        "\n",
        "    Input -> Conv1 -> BNorm1 -> ReLU -> MaxPool -> Layer1 -> Layer2 -> Layer3 -> Layer4 -> AvgPool -> FC\n",
        "\n",
        "    Args:\n",
        "        layers: A four value array containing number of conv layers in each residual block\n",
        "        input_channels: number of input channels\n",
        "        classes: Number of classes in the dataset\n",
        "\n",
        "    Methods:\n",
        "        _layer(num_layers (Number of conv layers)\n",
        "               ,input_channels (Number of input channels)\n",
        "               ,output_channels (Number of output channels)\n",
        "               ,stride (Stride value for conv layer)) :-\n",
        "        Returns the sequential wrapper with all the layers in the residual block constructed according\n",
        "        to the parameters.\n",
        "\n",
        "        forward(inp) :-\n",
        "        Applies the sequence of operations mentioned above.\n",
        "        (batch_size, input_channels, height, width) -> (batch_size, classes)\n",
        "\n",
        "    Examples:\n",
        "        >>> resnet = ResNetLarge(layers, input_channels, classes)\n",
        "        >>> out = resnet(inp)\n",
        "    '''\n",
        "    def __init__(self, layers, input_channels, classes):\n",
        "        super(ResNetLarge, self).__init__()\n",
        "        self.name = 'ResNet'\n",
        "        self.conv1 = nn.Conv2d(input_channels, 64, kernel_size=7, stride=2, padding=3)\n",
        "        self.bnorm1 = nn.BatchNorm2d(64)\n",
        "        self.activation = nn.ReLU()\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "        self.layer1 = self._layer(layers[0], input_channels=64, output_channels=64, stride=1)\n",
        "        self.layer2 = self._layer(layers[1], input_channels=256, output_channels=128, stride=2)\n",
        "        self.layer3 = self._layer(layers[2], input_channels=512, output_channels=256, stride=2)\n",
        "        self.layer4 = self._layer(layers[3], input_channels=1024, output_channels=512, stride=2)\n",
        "\n",
        "        self.avppool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(2048, classes)\n",
        "\n",
        "    def forward(self, inp):\n",
        "        # inp: (batch_size, input_channels, height, width)\n",
        "\n",
        "        out = self.activation(self.bnorm1(self.conv1(inp)))\n",
        "        out = self.maxpool(out)\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "\n",
        "        out = self.avppool(out)\n",
        "        out = out.reshape(out.shape[0], -1)\n",
        "        out = self.fc(out)\n",
        "\n",
        "        # out: (batch_size, classes)\n",
        "        return out\n",
        "\n",
        "    def _layer(self, num_layers, input_channels, output_channels, stride):\n",
        "        residual_downsample = None\n",
        "        layers = []\n",
        "\n",
        "        # Checks if there would be potential mismatch in any of height, width or channels between input and output.\n",
        "        # 4 is the value of the expansion for large ResNets\n",
        "        if stride != 1 or input_channels != output_channels * 4:\n",
        "            residual_downsample = nn.Sequential(\n",
        "                nn.Conv2d(input_channels, output_channels * 4, kernel_size=1, stride=stride),\n",
        "                nn.BatchNorm2d(output_channels * 4)\n",
        "            )\n",
        "\n",
        "        layers.append(ResidualBlockLarge(input_channels, output_channels, residual_downsample, stride))\n",
        "\n",
        "        for i in range(num_layers - 1):\n",
        "            layers.append(ResidualBlockLarge(output_channels * 4, output_channels))\n",
        "\n",
        "        return nn.Sequential(*layers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "4piMb4xwl3MX"
      },
      "outputs": [],
      "source": [
        "def ResNet34(input_channels, classes):\n",
        "    '''\n",
        "    Initalization of ResNet34 using the layers as mentioned in the paper and using ResNetSmall module.\n",
        "\n",
        "    Args:\n",
        "        input_channels: Number of input channels\n",
        "        classes: Number of classes in the dataset\n",
        "\n",
        "    Output:\n",
        "        ResNetSmall Object\n",
        "    '''\n",
        "    return ResNetSmall([3, 4, 6, 3], input_channels, classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "GeceF_RUaVO4"
      },
      "outputs": [],
      "source": [
        "def ResNet50(input_channels, classes):\n",
        "    '''\n",
        "    Initalization of ResNet50 using the layers as mentioned in the paper and using ResNetLarge module.\n",
        "\n",
        "    Args:\n",
        "        input_channels: Number of input channels\n",
        "        classes: Number of classes in the dataset\n",
        "\n",
        "    Output:\n",
        "        ResNetLarge Object\n",
        "    '''\n",
        "    return ResNetLarge([3, 4, 6, 3], input_channels, classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bGS4bmCRWmIg"
      },
      "source": [
        "#### Data Loading Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "pgUkmwvcf1hJ"
      },
      "outputs": [],
      "source": [
        "def create_data_sampler(dataset_size, split_size, seed=42):\n",
        "    \"\"\"\n",
        "    Create a sampler for dataset splitting\n",
        "\n",
        "    Args:\n",
        "        dataset_size: Total size of the dataset\n",
        "        split_size: Size of the split needed\n",
        "        seed: Random seed\n",
        "    Returns:\n",
        "        torch.utils.data.Sampler object\n",
        "    \"\"\"\n",
        "    indices = list(range(dataset_size))\n",
        "    np.random.seed(seed)\n",
        "    np.random.shuffle(indices)\n",
        "    return SubsetRandomSampler(indices[:split_size])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "zP6WubQp9swB"
      },
      "outputs": [],
      "source": [
        "def get_transforms(size='32', normalize='standard', is_training=True):\n",
        "    \"\"\"\n",
        "    Get data transforms for CIFAR100\n",
        "\n",
        "    Args:\n",
        "        size: Image size ('32' or '224')\n",
        "        normalize: Normalization type ('standard' or 'imagenet')\n",
        "        is_training: Whether to include augmentation transforms\n",
        "    Returns:\n",
        "        torchvision.transforms.Compose object\n",
        "    \"\"\"\n",
        "    if normalize == 'imagenet':\n",
        "        mean, std = [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]\n",
        "    else:\n",
        "        mean, std = [0.5, 0.5, 0.5], [0.5, 0.5, 0.5]\n",
        "\n",
        "    transforms_list = []\n",
        "\n",
        "    # Add data augmentation for training\n",
        "    if is_training:\n",
        "        if size == '32':\n",
        "            transforms_list.extend([\n",
        "                transforms.RandomCrop(32, padding=4),\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.RandomRotation(15)\n",
        "            ])\n",
        "        else:  # size == '224'\n",
        "            transforms_list.append(\n",
        "                transforms.RandomResizedCrop((224, 224), scale=(0.8, 1.0))\n",
        "            )\n",
        "    elif size == '224':  # For validation/test with size 224\n",
        "        transforms_list.append(transforms.Resize((224, 224)))\n",
        "\n",
        "    # Add basic transforms\n",
        "    transforms_list.extend([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean, std)\n",
        "    ])\n",
        "\n",
        "    return transforms.Compose(transforms_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "60fXexWWWlpJ"
      },
      "outputs": [],
      "source": [
        "def CIFAR100DataLoader(split= 'train',\n",
        "                       batch_size=8,\n",
        "                       num_workers=2,\n",
        "                       shuffle=True,\n",
        "                       size='32',\n",
        "                       normalize='standard',\n",
        "                       train_size=45000,\n",
        "                       val_size=5000,\n",
        "                       seed=42):\n",
        "    '''\n",
        "    A wrapper function that creates a DataLoader for CIFAR100 dataset loaded from torchvision using\n",
        "    the parameters supplied and applies the required data augmentations.\n",
        "\n",
        "    Args:\n",
        "        split: (string Values: 'train', 'valt' hoặc 'test')\n",
        "        batch_size: Batch size to used for loading data (Default=8)\n",
        "        num_workers: Number of parallel workers used to load data (Default=2)\n",
        "        shuffle: Boolean value to decide if data should be randomized (Default=True)\n",
        "        size: A string to decide the size of the input images (Default='32') (Values: '32','224')\n",
        "        normalize: A string to decide the normalization to applied to the input images\n",
        "                   (Default='standard') (Values: 'standard', 'imagenet')\n",
        "        train_size: Number of training samples\n",
        "        val_size: Number of validation samples\n",
        "        seed: Random seed\n",
        "\n",
        "    Output:\n",
        "        torch.utils.data.DataLoader object\n",
        "    '''\n",
        "    # Set seed for reproducibility\n",
        "    torch.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "\n",
        "    # Get appropriate transforms\n",
        "    is_training = (split == 'train')\n",
        "    transforms = get_transforms(size, normalize, is_training)\n",
        "\n",
        "    if split in ['train', 'val']:\n",
        "        dataset = torchvision.datasets.CIFAR100(\n",
        "            root='./data',\n",
        "            train=True,\n",
        "            download=True,\n",
        "            transform=transforms\n",
        "        )\n",
        "\n",
        "        # Chia dữ liệu train và val\n",
        "        if split == 'train':\n",
        "            sampler = create_data_sampler(len(dataset), train_size, seed)\n",
        "        else:  # val\n",
        "            val_indices = list(range(len(dataset)))[train_size:train_size + val_size]\n",
        "            sampler = SubsetRandomSampler(val_indices)\n",
        "\n",
        "        dataloader = DataLoader(\n",
        "            dataset,\n",
        "            batch_size=batch_size,\n",
        "            num_workers=num_workers,\n",
        "            sampler=sampler\n",
        "        )\n",
        "\n",
        "    else:  # test\n",
        "        dataset = torchvision.datasets.CIFAR100(\n",
        "            root='./data',\n",
        "            train=False,\n",
        "            download=True,\n",
        "            transform=transforms\n",
        "        )\n",
        "\n",
        "        dataloader = DataLoader(\n",
        "            dataset,\n",
        "            batch_size=batch_size,\n",
        "            num_workers=num_workers,\n",
        "            shuffle=shuffle\n",
        "        )\n",
        "\n",
        "    return dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "uoxARUbUBrpV"
      },
      "outputs": [],
      "source": [
        "def load_cifar100_data(\n",
        "    batch_size=32,\n",
        "    num_workers=2,\n",
        "    size='32',\n",
        "    normalize='standard',\n",
        "    train_size=45000,\n",
        "    val_size=5000,\n",
        "    seed=42\n",
        "):\n",
        "    \"\"\"\n",
        "    Load all CIFAR100 dataloaders\n",
        "\n",
        "    Args:\n",
        "        batch_size: Batch size\n",
        "        num_workers: Number of workers\n",
        "        size: Image size ('32' or '224')\n",
        "        normalize: Normalization type ('standard' or 'imagenet')\n",
        "        train_size: Number of training samples\n",
        "        val_size: Number of validation samples\n",
        "        seed: Random seed\n",
        "    Returns:\n",
        "        train_loader, val_loader, test_loader\n",
        "    \"\"\"\n",
        "    train_loader = CIFAR100DataLoader(\n",
        "        split='train',\n",
        "        batch_size=batch_size,\n",
        "        num_workers=num_workers,\n",
        "        shuffle=True,\n",
        "        size=size,\n",
        "        normalize=normalize,\n",
        "        train_size=train_size,\n",
        "        val_size=val_size,\n",
        "        seed=seed\n",
        "    )\n",
        "\n",
        "    val_loader = CIFAR100DataLoader(\n",
        "        split='val',\n",
        "        batch_size=batch_size,\n",
        "        num_workers=num_workers,\n",
        "        shuffle=False,\n",
        "        size=size,\n",
        "        normalize=normalize,\n",
        "        train_size=train_size,\n",
        "        val_size=val_size,\n",
        "        seed=seed\n",
        "    )\n",
        "\n",
        "    test_loader = CIFAR100DataLoader(\n",
        "        split='test',\n",
        "        batch_size=batch_size,\n",
        "        num_workers=num_workers,\n",
        "        shuffle=False,\n",
        "        size=size,\n",
        "        normalize=normalize,\n",
        "        train_size=train_size,\n",
        "        val_size=val_size,\n",
        "        seed=seed\n",
        "    )\n",
        "\n",
        "    # Print dataset information\n",
        "    print(f'Dataset sizes:')\n",
        "    print(f'Training:   {train_size:,} images')\n",
        "    print(f'Validation: {val_size:,} images')\n",
        "    print(f'Test:       {10000:,} images')\n",
        "\n",
        "    return train_loader, val_loader, test_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RtYCa72d0RJ6"
      },
      "outputs": [],
      "source": [
        "def CIFAR10DataLoader(split, batch_size=8, num_workers=2, shuffle=True, size='32', normalize='standard'):\n",
        "    '''\n",
        "    A wrapper function that creates a DataLoader for CIFAR10 dataset loaded from torchvision using\n",
        "    the parameters supplied and applies the required data augmentations.\n",
        "\n",
        "    Args:\n",
        "        split: (string Values: 'train', 'valt' hoặc 'test')\n",
        "        batch_size: Batch size to used for loading data (Default=8)\n",
        "        num_workers: Number of parallel workers used to load data (Default=2)\n",
        "        shuffle: Boolean value to decide if data should be randomized (Default=True)\n",
        "        size: A string to decide the size of the input images (Default='32') (Values: '32','224')\n",
        "        normalize: A string to decide the normalization to applied to the input images\n",
        "                   (Default='standard') (Values: 'standard', 'imagenet')\n",
        "\n",
        "    Output:\n",
        "        DataLoader Object\n",
        "    '''\n",
        "    if normalize == 'imagenet':\n",
        "        mean = [0.485, 0.456, 0.406]\n",
        "        std = [0.229, 0.224, 0.225]\n",
        "    elif normalize == 'standard':\n",
        "        mean = [0.5, 0.5, 0.5]\n",
        "        std =  [0.5, 0.5, 0.5]\n",
        "\n",
        "    if split == 'train':\n",
        "        if size == '224':\n",
        "            train_transform = transforms.Compose([\n",
        "                transforms.RandomResizedCrop((224,224), scale=(0.5, 1.0)),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize(mean, std)\n",
        "            ])\n",
        "        elif size == '32':\n",
        "            train_transform = transforms.Compose([\n",
        "                transforms.Resize((48, 48)),\n",
        "                transforms.RandomCrop(32),\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.RandomRotation(15),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize(mean, std)\n",
        "            ])\n",
        "\n",
        "        cifar10 = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=train_transform)\n",
        "        dataloader = DataLoader(cifar10, batch_size=batch_size, num_workers=num_workers, shuffle=shuffle)\n",
        "\n",
        "    elif split == 'test':\n",
        "        if size == '224':\n",
        "            test_transform = transforms.Compose([\n",
        "                transforms.Resize((224, 224)),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize(mean, std)\n",
        "            ])\n",
        "        elif size == '32':\n",
        "            test_transform = transforms.Compose([\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize(mean, std)\n",
        "            ])\n",
        "\n",
        "        cifar10 = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=test_transform)\n",
        "        dataloader = DataLoader(cifar10, batch_size=batch_size, num_workers=num_workers, shuffle=shuffle)\n",
        "\n",
        "    return dataloader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UB_YjSG0aLJR"
      },
      "source": [
        "#### Training and Evaluation Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "Byfz7zrEaKxq"
      },
      "outputs": [],
      "source": [
        "# Initializations of all the constants used in the training and testing process\n",
        "\n",
        "lr = 0.003\n",
        "batch_size = 32 #256\n",
        "num_workers = 2\n",
        "shuffle = True\n",
        "patch_size = 16 #4\n",
        "image_sz = 32\n",
        "max_len = 1000 # All sequences must be less than 1000 including class token\n",
        "embed_dim = 768\n",
        "classes = 100\n",
        "layers = 12\n",
        "channels = 3\n",
        "resnet_features_channels = 64\n",
        "heads = 12\n",
        "epochs = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "d89pJGwZaUBs"
      },
      "outputs": [],
      "source": [
        "def train(model, dataloader, criterion, optimizer, scheduler, resnet_features=None):\n",
        "    '''\n",
        "    Function used to train the model over a single epoch and update it according to the\n",
        "    calculated gradients.\n",
        "\n",
        "    Args:\n",
        "        model: Model supplied to the function\n",
        "        dataloader: DataLoader supplied to the function\n",
        "        criterion: Criterion used to calculate loss\n",
        "        optimizer: Optimizer used update the model\n",
        "        scheduler: Scheduler used to update the learing rate for faster convergence\n",
        "                   (Commented out due to poor results)\n",
        "        resnet_features: Model to get Resnet Features for the hybrid architecture (Default=None)\n",
        "\n",
        "    Output:\n",
        "        running_loss: Training Loss (Float)\n",
        "        running_accuracy: Training Accuracy (Float)\n",
        "    '''\n",
        "    running_loss = 0.0\n",
        "    running_accuracy = 0.0\n",
        "\n",
        "    for data, target in tqdm(dataloader):\n",
        "        data = data.to(device)\n",
        "        target = target.to(device)\n",
        "\n",
        "        if model.name == 'VisionTransformer':\n",
        "            with torch.no_grad():\n",
        "                if resnet_features != None:\n",
        "                    data = resnet_features(data)\n",
        "            output, _ = model(data)\n",
        "        elif model.name == 'ResNet':\n",
        "            output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        # scheduler.step()\n",
        "\n",
        "        acc = (output.argmax(dim=1) == target).float().mean()\n",
        "        running_accuracy += acc / len(dataloader)\n",
        "        running_loss += loss.item() / len(dataloader)\n",
        "\n",
        "    return running_loss, running_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "dXAFKy14EIyU"
      },
      "outputs": [],
      "source": [
        "def evaluation(model, dataloader, criterion, resnet_features=None):\n",
        "    '''\n",
        "    Function used to evaluate the model on the test dataset.\n",
        "\n",
        "    Args:\n",
        "        model: Model supplied to the function\n",
        "        dataloader: DataLoader supplied to the function\n",
        "        criterion: Criterion used to calculate loss\n",
        "        resnet_features: Model to get Resnet Features for the hybrid architecture (Default=None)\n",
        "\n",
        "    Output:\n",
        "        test_loss: Testing Loss (Float)\n",
        "        test_accuracy: Testing Accuracy (Float)\n",
        "    '''\n",
        "    with torch.no_grad():\n",
        "        test_accuracy = 0.0\n",
        "        test_loss = 0.0\n",
        "        for data, target in tqdm(dataloader):\n",
        "            data = data.to(device)\n",
        "            target = target.to(device)\n",
        "\n",
        "            if model.name == 'VisionTransformer':\n",
        "                if resnet_features != None:\n",
        "                    data = resnet_features(data)\n",
        "                output, _ = model(data)\n",
        "            elif model.name == 'ResNet':\n",
        "                output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "\n",
        "            acc = (output.argmax(dim=1) == target).float().mean()\n",
        "            test_accuracy += acc / len(dataloader)\n",
        "            test_loss += loss.item() / len(dataloader)\n",
        "\n",
        "    return test_loss, test_accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1NNc-FxvJU7"
      },
      "source": [
        "#### Model Initialization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94FIkGknvMUW"
      },
      "source": [
        "Run either one the following subcells according to the models selected to train and test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofAkCvMzfN3R"
      },
      "source": [
        "##### Model - Vision Transformer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVBkOJnnvWzH"
      },
      "source": [
        "Recommended Values for the following Architecture\n",
        "\n",
        "- patch_size = 4\n",
        "- max_len = 100\n",
        "- embed_dim = 512\n",
        "- classes = According to Dataset\n",
        "- layers = 12\n",
        "- channels = 3\n",
        "- heads = 16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "WG_wT7pXe5q9",
        "outputId": "bdfa918b-bf06-4c59-be20-b5f685eb76aa"
      },
      "outputs": [],
      "source": [
        "# Vision Transformer Architecture\n",
        "\n",
        "model = VisionTransformer(\n",
        "    patch_size=patch_size,\n",
        "    max_len=max_len,\n",
        "    embed_dim=embed_dim,\n",
        "    classes=classes,\n",
        "    layers=layers,\n",
        "    channels=channels,\n",
        "    heads=heads).to(device)\n",
        "\n",
        "resnet_features = None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-AtT5cLKvtxC"
      },
      "source": [
        "Recommended Values for the following Architecture\n",
        "\n",
        "- patch_size = 7\n",
        "- max_len = 100\n",
        "- embed_dim = 512\n",
        "- classes = According to Dataset\n",
        "- layers = 12\n",
        "- channels = 64 (Resnet Features Channels)\n",
        "- heads = 16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MrWmtB8QVT50",
        "outputId": "feb22db2-0f44-4ecf-99dc-2bfb75b0e9de"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "# Hybrid Vision Transformer Architecture\n",
        "\n",
        "model = VisionTransformer(\n",
        "    patch_size=patch_size,\n",
        "    max_len=max_len,\n",
        "    embed_dim=embed_dim,\n",
        "    classes=classes,\n",
        "    layers=layers,\n",
        "    channels=resnet_features_channels,\n",
        "    heads=heads).to(device)\n",
        "\n",
        "resnet_features = ResNetFeatures().to(device).eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lq_fd2gjfRqD"
      },
      "source": [
        "##### Model - ResNet50 or ResNet34"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MduGlJkPwEmp"
      },
      "source": [
        "Recommended Values for the following Architecture\n",
        "\n",
        "- input_channels = 3\n",
        "- classes = According to Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NJhrjCYhmjII"
      },
      "outputs": [],
      "source": [
        "# ResNet34 Architecture\n",
        "\n",
        "model = ResNet34(\n",
        "    input_channels=3,\n",
        "    classes=classes).to(device)\n",
        "\n",
        "resnet_features = None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQzAinFRwMcw"
      },
      "source": [
        "Recommended Values for the following Architecture\n",
        "\n",
        "- input_channels = 3\n",
        "- classes = According to Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nztkBOLRe6pO"
      },
      "outputs": [],
      "source": [
        "# ResNet50 Architecture\n",
        "\n",
        "model = ResNet50(\n",
        "    input_channels=3,\n",
        "    classes=classes).to(device)\n",
        "\n",
        "resnet_features = None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0x9qE4HhUhR"
      },
      "source": [
        "#### Model Training and Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7yDEtyzw8oU"
      },
      "source": [
        "##### CIFAR100 Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "6iN8EeU6CN5f"
      },
      "outputs": [],
      "source": [
        "tenmohinh = 'm1'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pp1l68Z_UiGc",
        "outputId": "17d99bd9-f054-4ca2-81fc-4b604be38a55"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ./data/cifar-100-python.tar.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 169001437/169001437 [01:18<00:00, 2147510.76it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-100-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Dataset sizes:\n",
            "Training:   45,000 images\n",
            "Validation: 5,000 images\n",
            "Test:       10,000 images\n"
          ]
        }
      ],
      "source": [
        "train_dataloader, val_dataloader, test_dataloader = load_cifar100_data(batch_size=32,\n",
        "                                                           num_workers=2,\n",
        "                                                           size='32',\n",
        "                                                           normalize='standard',\n",
        "                                                           train_size=45000,\n",
        "                                                           val_size=5000) # mặc định test = 10000\n",
        "\n",
        "criterion = nn.CrossEntropyLoss().to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=lr, steps_per_epoch=len(train_dataloader), epochs=epochs)\n",
        "\n",
        "train_accs = []\n",
        "test_accs = []\n",
        "\n",
        "checkpoint_dir = os.path.join(work_dir, 'checkpoints')\n",
        "os.makedirs(checkpoint_dir, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hlRd6gC3lBmt",
        "outputId": "36ac9904-7143-4fab-99e7-ee2ad78abe7f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1407/1407 [01:13<00:00, 19.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 1 - acc: 0.0312 - loss : 4.4426\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 313/313 [00:04<00:00, 74.47it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test acc: 0.0509 - test loss : 4.2500\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1407/1407 [01:15<00:00, 18.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 2 - acc: 0.0665 - loss : 4.1298\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 313/313 [00:04<00:00, 72.98it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test acc: 0.0835 - test loss : 4.0075\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1407/1407 [01:14<00:00, 18.94it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 3 - acc: 0.0918 - loss : 3.9383\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 313/313 [00:04<00:00, 73.67it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test acc: 0.1055 - test loss : 3.8439\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1407/1407 [01:13<00:00, 19.21it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 4 - acc: 0.1069 - loss : 3.8384\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 313/313 [00:04<00:00, 71.99it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test acc: 0.1211 - test loss : 3.7583\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1407/1407 [01:12<00:00, 19.35it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 5 - acc: 0.1177 - loss : 3.7787\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 313/313 [00:04<00:00, 75.32it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test acc: 0.1302 - test loss : 3.7154\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1407/1407 [01:12<00:00, 19.42it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 6 - acc: 0.1207 - loss : 3.7437\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 313/313 [00:04<00:00, 67.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test acc: 0.1234 - test loss : 3.7580\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1407/1407 [01:11<00:00, 19.71it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 7 - acc: 0.1294 - loss : 3.6985\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 313/313 [00:04<00:00, 73.27it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test acc: 0.1275 - test loss : 3.7217\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1407/1407 [01:12<00:00, 19.45it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 8 - acc: 0.1312 - loss : 3.6799\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 313/313 [00:04<00:00, 73.32it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test acc: 0.1333 - test loss : 3.7002\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1407/1407 [01:13<00:00, 19.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 9 - acc: 0.1362 - loss : 3.6487\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 313/313 [00:04<00:00, 72.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test acc: 0.1315 - test loss : 3.6990\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1407/1407 [01:14<00:00, 18.78it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 10 - acc: 0.1390 - loss : 3.6277\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 313/313 [00:04<00:00, 71.41it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test acc: 0.1365 - test loss : 3.6855\n",
            "\n",
            "Saved checkpoint at epoch 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1407/1407 [01:13<00:00, 19.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 11 - acc: 0.1468 - loss : 3.6077\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 313/313 [00:04<00:00, 70.00it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test acc: 0.1406 - test loss : 3.6844\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1407/1407 [01:11<00:00, 19.60it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 12 - acc: 0.1445 - loss : 3.6016\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 313/313 [00:04<00:00, 72.59it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test acc: 0.1456 - test loss : 3.6306\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1407/1407 [01:12<00:00, 19.46it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 13 - acc: 0.1507 - loss : 3.5745\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 313/313 [00:04<00:00, 75.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test acc: 0.1498 - test loss : 3.6089\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1407/1407 [01:12<00:00, 19.31it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 14 - acc: 0.1505 - loss : 3.5759\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 313/313 [00:04<00:00, 75.64it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test acc: 0.1489 - test loss : 3.6067\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1407/1407 [01:12<00:00, 19.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 15 - acc: 0.1539 - loss : 3.5504\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 313/313 [00:04<00:00, 70.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test acc: 0.1458 - test loss : 3.6552\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1407/1407 [01:12<00:00, 19.49it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 16 - acc: 0.1564 - loss : 3.5504\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 313/313 [00:04<00:00, 73.29it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test acc: 0.1406 - test loss : 3.6378\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1407/1407 [01:12<00:00, 19.36it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 17 - acc: 0.1567 - loss : 3.5397\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 313/313 [00:04<00:00, 74.29it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test acc: 0.1388 - test loss : 3.6920\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1407/1407 [01:12<00:00, 19.45it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 18 - acc: 0.1514 - loss : 3.5516\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 313/313 [00:04<00:00, 72.47it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test acc: 0.1505 - test loss : 3.6285\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1407/1407 [01:11<00:00, 19.71it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 19 - acc: 0.1539 - loss : 3.5402\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 313/313 [00:04<00:00, 74.34it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test acc: 0.1525 - test loss : 3.5924\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1407/1407 [01:12<00:00, 19.29it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 20 - acc: 0.1553 - loss : 3.5333\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 313/313 [00:04<00:00, 74.67it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test acc: 0.1537 - test loss : 3.6282\n",
            "\n",
            "Saved checkpoint at epoch 20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1407/1407 [01:11<00:00, 19.55it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 21 - acc: 0.1601 - loss : 3.5170\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 313/313 [00:04<00:00, 75.83it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test acc: 0.1548 - test loss : 3.5989\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1407/1407 [01:12<00:00, 19.49it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 22 - acc: 0.1617 - loss : 3.5114\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 313/313 [00:04<00:00, 72.89it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test acc: 0.1505 - test loss : 3.6544\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1407/1407 [01:14<00:00, 19.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 23 - acc: 0.1592 - loss : 3.5087\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 313/313 [00:04<00:00, 66.71it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test acc: 0.1517 - test loss : 3.6377\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1407/1407 [01:17<00:00, 18.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 24 - acc: 0.1588 - loss : 3.5263\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 313/313 [00:04<00:00, 67.02it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test acc: 0.1384 - test loss : 3.6628\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1407/1407 [01:18<00:00, 18.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 25 - acc: 0.1566 - loss : 3.5378\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 313/313 [00:04<00:00, 64.32it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test acc: 0.1544 - test loss : 3.6173\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1407/1407 [01:17<00:00, 18.04it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 26 - acc: 0.1570 - loss : 3.5217\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 313/313 [00:04<00:00, 70.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test acc: 0.1499 - test loss : 3.6421\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1407/1407 [01:19<00:00, 17.67it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 27 - acc: 0.1612 - loss : 3.5229\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 313/313 [00:04<00:00, 69.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test acc: 0.1509 - test loss : 3.6274\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1407/1407 [01:19<00:00, 17.79it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 28 - acc: 0.1574 - loss : 3.5249\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 313/313 [00:04<00:00, 67.45it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test acc: 0.1448 - test loss : 3.6342\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1407/1407 [01:19<00:00, 17.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 29 - acc: 0.1535 - loss : 3.5428\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 313/313 [00:04<00:00, 64.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test acc: 0.1424 - test loss : 3.6730\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1407/1407 [01:18<00:00, 17.92it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 30 - acc: 0.1526 - loss : 3.5663\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 313/313 [00:04<00:00, 63.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test acc: 0.1340 - test loss : 3.7761\n",
            "\n",
            "Saved checkpoint at epoch 30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1407/1407 [01:19<00:00, 17.78it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 31 - acc: 0.1491 - loss : 3.5835\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 313/313 [00:04<00:00, 65.52it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test acc: 0.1389 - test loss : 3.6919\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1407/1407 [01:17<00:00, 18.08it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 32 - acc: 0.1564 - loss : 3.5435\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 313/313 [00:04<00:00, 68.29it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test acc: 0.1473 - test loss : 3.6508\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1407/1407 [01:18<00:00, 17.95it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 33 - acc: 0.1599 - loss : 3.5154\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 313/313 [00:04<00:00, 67.27it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test acc: 0.1512 - test loss : 3.6168\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1407/1407 [01:18<00:00, 18.00it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 34 - acc: 0.1606 - loss : 3.5273\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 313/313 [00:04<00:00, 65.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test acc: 0.1432 - test loss : 3.6793\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1407/1407 [01:18<00:00, 17.82it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 35 - acc: 0.1584 - loss : 3.5384\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 313/313 [00:04<00:00, 64.14it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test acc: 0.1224 - test loss : 3.8141\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1407/1407 [01:19<00:00, 17.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 36 - acc: 0.1569 - loss : 3.5496\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 313/313 [00:04<00:00, 68.31it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test acc: 0.1496 - test loss : 3.6791\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1407/1407 [01:17<00:00, 18.04it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 37 - acc: 0.1589 - loss : 3.5226\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 313/313 [00:04<00:00, 66.64it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test acc: 0.1483 - test loss : 3.6574\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1407/1407 [01:14<00:00, 18.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 38 - acc: 0.1581 - loss : 3.5373\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 313/313 [00:04<00:00, 75.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test acc: 0.1489 - test loss : 3.6635\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1407/1407 [01:12<00:00, 19.30it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 39 - acc: 0.1580 - loss : 3.5287\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 313/313 [00:04<00:00, 74.55it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test acc: 0.1514 - test loss : 3.6524\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1407/1407 [01:11<00:00, 19.67it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 40 - acc: 0.1560 - loss : 3.5392\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 313/313 [00:04<00:00, 70.26it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test acc: 0.1514 - test loss : 3.6484\n",
            "\n",
            "Saved checkpoint at epoch 40\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1407/1407 [01:11<00:00, 19.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 41 - acc: 0.1506 - loss : 3.5645\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 313/313 [00:04<00:00, 72.37it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test acc: 0.1434 - test loss : 3.6915\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1407/1407 [01:06<00:00, 21.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 42 - acc: 0.1554 - loss : 3.5551\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 313/313 [00:03<00:00, 78.34it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test acc: 0.1372 - test loss : 3.7130\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1407/1407 [01:09<00:00, 20.29it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 43 - acc: 0.1441 - loss : 3.6117\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 313/313 [00:03<00:00, 82.91it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test acc: 0.1268 - test loss : 3.7978\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1407/1407 [01:06<00:00, 21.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 44 - acc: 0.1455 - loss : 3.6230\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 313/313 [00:03<00:00, 89.29it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test acc: 0.1351 - test loss : 3.7367\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1407/1407 [00:58<00:00, 23.95it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 45 - acc: 0.1512 - loss : 3.5659\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 313/313 [00:03<00:00, 100.62it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test acc: 0.1349 - test loss : 3.7125\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1407/1407 [00:55<00:00, 25.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 46 - acc: 0.1520 - loss : 3.5691\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 313/313 [00:03<00:00, 87.09it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test acc: 0.1365 - test loss : 3.7200\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1407/1407 [00:57<00:00, 24.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 47 - acc: 0.1490 - loss : 3.5858\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 313/313 [00:03<00:00, 94.13it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test acc: 0.1317 - test loss : 3.7383\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1407/1407 [00:57<00:00, 24.57it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 48 - acc: 0.1532 - loss : 3.5705\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 313/313 [00:03<00:00, 98.95it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test acc: 0.1315 - test loss : 3.7347\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1407/1407 [01:01<00:00, 22.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 49 - acc: 0.1525 - loss : 3.5732\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 313/313 [00:03<00:00, 87.54it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test acc: 0.1404 - test loss : 3.7136\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1407/1407 [01:16<00:00, 18.34it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 50 - acc: 0.1545 - loss : 3.5526\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 313/313 [00:04<00:00, 74.02it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test acc: 0.1335 - test loss : 3.7737\n",
            "\n",
            "Saved checkpoint at epoch 50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1407/1407 [01:10<00:00, 19.92it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 51 - acc: 0.1534 - loss : 3.5645\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 313/313 [00:04<00:00, 74.55it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test acc: 0.1361 - test loss : 3.7427\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1407/1407 [01:11<00:00, 19.62it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 52 - acc: 0.1544 - loss : 3.5580\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 313/313 [00:04<00:00, 71.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test acc: 0.1334 - test loss : 3.7486\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1407/1407 [01:11<00:00, 19.59it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 53 - acc: 0.1525 - loss : 3.5578\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 313/313 [00:04<00:00, 75.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test acc: 0.1343 - test loss : 3.7515\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1407/1407 [01:11<00:00, 19.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 54 - acc: 0.1507 - loss : 3.5807\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 313/313 [00:04<00:00, 74.57it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test acc: 0.1421 - test loss : 3.7008\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1407/1407 [01:09<00:00, 20.30it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 55 - acc: 0.1470 - loss : 3.6016\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 313/313 [00:04<00:00, 76.43it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test acc: 0.1249 - test loss : 3.7965\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1407/1407 [01:11<00:00, 19.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 56 - acc: 0.1531 - loss : 3.5728\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 313/313 [00:04<00:00, 74.92it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test acc: 0.1429 - test loss : 3.6793\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1407/1407 [01:10<00:00, 20.09it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 57 - acc: 0.1547 - loss : 3.5517\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 313/313 [00:04<00:00, 78.08it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test acc: 0.1474 - test loss : 3.6930\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1407/1407 [01:09<00:00, 20.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 58 - acc: 0.1555 - loss : 3.5486\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 313/313 [00:04<00:00, 74.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test acc: 0.1415 - test loss : 3.7438\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1407/1407 [01:12<00:00, 19.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 59 - acc: 0.1533 - loss : 3.5778\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 313/313 [00:04<00:00, 75.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test acc: 0.1405 - test loss : 3.7446\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1407/1407 [01:09<00:00, 20.30it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 60 - acc: 0.1529 - loss : 3.5842\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 313/313 [00:04<00:00, 76.12it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test acc: 0.1314 - test loss : 3.8293\n",
            "\n",
            "Saved checkpoint at epoch 60\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1407/1407 [01:09<00:00, 20.27it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 61 - acc: 0.1440 - loss : 3.6138\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 313/313 [00:04<00:00, 75.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test acc: 0.1303 - test loss : 3.8075\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1407/1407 [01:10<00:00, 20.08it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 62 - acc: 0.1459 - loss : 3.6070\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 313/313 [00:04<00:00, 76.99it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test acc: 0.1219 - test loss : 3.8237\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1407/1407 [01:09<00:00, 20.15it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 63 - acc: 0.1402 - loss : 3.6462\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 313/313 [00:04<00:00, 70.98it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test acc: 0.1325 - test loss : 3.7476\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1407/1407 [01:10<00:00, 20.00it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 64 - acc: 0.1455 - loss : 3.6177\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 313/313 [00:03<00:00, 78.35it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test acc: 0.1255 - test loss : 3.7820\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1407/1407 [01:10<00:00, 20.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 65 - acc: 0.1425 - loss : 3.6402\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 313/313 [00:04<00:00, 73.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test acc: 0.1212 - test loss : 3.8071\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1407/1407 [01:11<00:00, 19.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 66 - acc: 0.1431 - loss : 3.6369\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 313/313 [00:04<00:00, 73.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test acc: 0.1171 - test loss : 3.8430\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1407/1407 [01:10<00:00, 19.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 67 - acc: 0.1384 - loss : 3.6570\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 313/313 [00:04<00:00, 74.62it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test acc: 0.1239 - test loss : 3.8345\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1407/1407 [01:11<00:00, 19.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 68 - acc: 0.1389 - loss : 3.6377\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 313/313 [00:04<00:00, 76.38it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test acc: 0.1093 - test loss : 3.9232\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1407/1407 [01:10<00:00, 19.83it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 69 - acc: 0.1401 - loss : 3.6437\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 313/313 [00:04<00:00, 77.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test acc: 0.1332 - test loss : 3.7582\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1407/1407 [01:09<00:00, 20.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 70 - acc: 0.1408 - loss : 3.6504\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 313/313 [00:04<00:00, 76.04it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test acc: 0.1254 - test loss : 3.7742\n",
            "\n",
            "Saved checkpoint at epoch 70\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1407/1407 [01:11<00:00, 19.81it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 71 - acc: 0.1418 - loss : 3.6357\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 313/313 [00:04<00:00, 74.92it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test acc: 0.1191 - test loss : 3.8253\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1407/1407 [01:09<00:00, 20.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 72 - acc: 0.1367 - loss : 3.6662\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 313/313 [00:04<00:00, 75.39it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test acc: 0.1137 - test loss : 3.8784\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 19%|█▉        | 265/1407 [00:13<00:58, 19.60it/s]"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "\n",
        "try:\n",
        "    for epoch in range(epochs):\n",
        "        # Training phase\n",
        "        running_loss, running_accuracy = train(model, train_dataloader, criterion,\n",
        "                                             optimizer, scheduler, resnet_features)\n",
        "        print(f\"Epoch : {epoch+1} - acc: {running_accuracy:.4f} - loss : {running_loss:.4f}\")\n",
        "        train_accs.append(running_accuracy)\n",
        "\n",
        "        # Evaluation phase\n",
        "        test_loss, test_accuracy = evaluation(model, test_dataloader, criterion, resnet_features)\n",
        "        print(f\"test acc: {test_accuracy:.4f} - test loss : {test_loss:.4f}\\n\")\n",
        "        test_accs.append(test_accuracy)\n",
        "\n",
        "        # Save checkpoint every 10 epochs\n",
        "        if (epoch+1) % 10 == 0:\n",
        "            checkpoint_path = os.path.join(checkpoint_dir,\n",
        "                                         f'{model.name}_{tenmohinh}_CIFAR100_epoch_{epoch+1}_checkpoint.pt')\n",
        "            torch.save({\n",
        "                'epoch': epoch,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'scheduler_state_dict': scheduler.state_dict(),\n",
        "                'train_acc': train_accs,\n",
        "                'test_acc': test_accs\n",
        "            }, checkpoint_path)\n",
        "            print(f\"Saved checkpoint at epoch {epoch+1}\")\n",
        "\n",
        "except KeyboardInterrupt:\n",
        "    print(\"\\nTraining interrupted by user. Saving final checkpoint...\")\n",
        "    final_checkpoint_path = os.path.join(checkpoint_dir,\n",
        "                                       f'{model.name}_{tenmohinh}_CIFAR100_interrupted_checkpoint.pt')\n",
        "    torch.save({\n",
        "        'epoch': epoch,\n",
        "        'model_state_dict': model.state_dict(), # Chỉ lưu các tham số (weights và biases) của mô hình\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'scheduler_state_dict': scheduler.state_dict(),\n",
        "        'train_acc': train_accs,\n",
        "        'test_acc': test_accs\n",
        "    }, final_checkpoint_path)\n",
        "    print(\"Final checkpoint saved.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred during training: {str(e)}\")\n",
        "\n",
        "finally:\n",
        "    # Tính tổng thời gian chạy\n",
        "    end_time = time.time()\n",
        "    total_time = end_time - start_time\n",
        "print(f\"Total training time: {str(timedelta(seconds=int(total_time)))}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4CAK2Or6qZve"
      },
      "outputs": [],
      "source": [
        "## Có thể load weights vào model có cấu trúc tương tự nhưng khác tên\n",
        "# class ModelV1(nn.Module):\n",
        "#     def __init__(self):\n",
        "#         super().__init__()\n",
        "#         self.conv1 = nn.Conv2d(3, 64, 3)\n",
        "\n",
        "# class ModelV2(nn.Module):\n",
        "#     def __init__(self):\n",
        "#         super().__init__()\n",
        "#         self.conv1 = nn.Conv2d(3, 64, 3)\n",
        "\n",
        "# #Load weights từ ModelV1 sang ModelV2\n",
        "# model_v1_checkpoint = torch.load('model_v1_checkpoint.pt')\n",
        "# model_v2 = ModelV2()\n",
        "# model_v2.load_state_dict(model_v1_checkpoint['model_state_dict'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4KjgBoZoxU42"
      },
      "source": [
        "##### Plotting Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WsB1V8Gl0jnQ"
      },
      "outputs": [],
      "source": [
        "train_accs = [acc.cpu().item() for acc in train_accs]\n",
        "test_accs = [acc.cpu().item() for acc in test_accs]\n",
        "# print(train_accs)\n",
        "# print(test_accs)\n",
        "plt.style.use('seaborn')\n",
        "plt.plot(range(1, 101), train_accs, label='Train Accuracy')\n",
        "plt.plot(range(1, 101), test_accs, label='Test Accuracy')\n",
        "\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "\n",
        "plt.title(\"Train vs Test Accuracy\")\n",
        "plt.legend(loc='lower right')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "LFc5EfTgZIBk"
      ],
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "andt",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
